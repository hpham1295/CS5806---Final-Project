{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e24b7431-21a0-41dc-8eaa-4d2f1733c5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b3f035d-276c-478a-9fd9-25af9a337ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Load full dataset ---\n",
    "file_path = 'C:/Users/anhuy/CS-5806/Project/data/raw'\n",
    "os.chdir(file_path)\n",
    "\n",
    "df_full = pd.read_csv('final_uhie_ulti.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e21f502-497a-4aa3-8a1a-0f55599c19ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial full dataset shape: (232651, 32)\n",
      "After rolling window fill, dataset shape: (232651, 32)\n",
      "Number of rows with missing values after rolling fill (full df_filled): 6333\n",
      "Shape of full cleaned dataset after dropping NaNs: (226318, 32)\n",
      "After subsampling from df_filled, dataset shape: (23266, 32)\n",
      "Number of rows with missing values after subsampling: 628\n",
      "After dropping NaNs from subsampled dataset, new shape: (22638, 32)\n",
      "Final feature matrix after subsampling shape: (22638, 30)\n",
      "Final target vector after subsampling shape: (22638,)\n",
      "Saved all files: X, y, lat_lon, and original_index for both full cleaned and subsampled datasets!\n"
     ]
    }
   ],
   "source": [
    "# --- Step 2: Preserve lat/lon for post-processing (mapping) ---\n",
    "lat_lon = df_full[['lat', 'lon']]\n",
    "\n",
    "# --- Step 3: Define columns to drop ---\n",
    "cols_to_drop = ['GEOID', 'lat', 'lon', 'area', 'geometry']\n",
    "\n",
    "# --- Step 4: Add original index for spatial traceability ---\n",
    "df_full['original_index'] = df_full.index\n",
    "\n",
    "# --- Step 5: Drop unnecessary columns ---\n",
    "df = df_full.drop(columns=cols_to_drop)\n",
    "\n",
    "print(f\"Initial full dataset shape: {df.shape}\")\n",
    "\n",
    "# --- Step 6: Replace bad entries with NaN ---\n",
    "df = df.replace('-', pd.NA)\n",
    "\n",
    "# --- Step 7: Convert everything to numeric ---\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# --- Step 8: Rolling Window Imputation (on full dataset) ---\n",
    "rolling_window_size = 10  # 5 before + center + 5 after\n",
    "df_filled = df.copy()\n",
    "\n",
    "for col in df_filled.columns:\n",
    "    df_filled[col] = df_filled[col].fillna(\n",
    "        df_filled[col].rolling(window=rolling_window_size, center=True, min_periods=1).mean()\n",
    "    )\n",
    "\n",
    "print(f\"After rolling window fill, dataset shape: {df_filled.shape}\")\n",
    "\n",
    "# --- Step 9: Full Cleaned Dataset (drop NaNs) ---\n",
    "num_remaining_nan_full = df_filled.isnull().any(axis=1).sum()\n",
    "print(f\"Number of rows with missing values after rolling fill (full df_filled): {num_remaining_nan_full}\")\n",
    "\n",
    "df_full_cleaned = df_filled.dropna()\n",
    "lat_lon_full_cleaned = lat_lon.loc[df_full_cleaned.index]\n",
    "original_index_full_cleaned = df_full.loc[df_full_cleaned.index, 'original_index']\n",
    "\n",
    "print(f\"Shape of full cleaned dataset after dropping NaNs: {df_full_cleaned.shape}\")\n",
    "\n",
    "# Separate features and target\n",
    "y_full_cleaned = df_full_cleaned['UHII']\n",
    "X_full_cleaned = df_full_cleaned.drop(columns=['UHII', 'original_index'])\n",
    "\n",
    "# --- Step 10: Subsampling from df_filled ---\n",
    "subsample_rate = 10\n",
    "df_subsampled = df_filled.iloc[::subsample_rate, :]\n",
    "lat_lon_subsampled = lat_lon.loc[df_subsampled.index]\n",
    "original_index_subsampled = df_full.loc[df_subsampled.index, 'original_index']\n",
    "\n",
    "print(f\"After subsampling from df_filled, dataset shape: {df_subsampled.shape}\")\n",
    "\n",
    "# --- Step 11: Drop any NaNs after subsampling ---\n",
    "num_remaining_nan_subsampled = df_subsampled.isnull().any(axis=1).sum()\n",
    "print(f\"Number of rows with missing values after subsampling: {num_remaining_nan_subsampled}\")\n",
    "\n",
    "if num_remaining_nan_subsampled > 0:\n",
    "    df_subsampled = df_subsampled.dropna()\n",
    "    lat_lon_subsampled = lat_lon_subsampled.loc[df_subsampled.index]\n",
    "    original_index_subsampled = original_index_subsampled.loc[df_subsampled.index]\n",
    "    print(f\"After dropping NaNs from subsampled dataset, new shape: {df_subsampled.shape}\")\n",
    "else:\n",
    "    print(\"No NaN rows to drop after subsampling.\")\n",
    "\n",
    "# Separate features and target\n",
    "y_subsampled = df_subsampled['UHII']\n",
    "X_subsampled = df_subsampled.drop(columns=['UHII', 'original_index'])\n",
    "\n",
    "print(f\"Final feature matrix after subsampling shape: {X_subsampled.shape}\")\n",
    "print(f\"Final target vector after subsampling shape: {y_subsampled.shape}\")\n",
    "\n",
    "# --- Step 12: Save datasets ---\n",
    "save_path = 'C:/Users/anhuy/CS-5806/Project/data/processed'\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# Save full cleaned\n",
    "X_full_cleaned.to_csv(os.path.join(save_path, 'X_full_cleaned.csv'), index=False)\n",
    "y_full_cleaned.to_csv(os.path.join(save_path, 'y_full_cleaned.csv'), index=False)\n",
    "lat_lon_full_cleaned.to_csv(os.path.join(save_path, 'lat_lon_full_cleaned.csv'), index=False)\n",
    "original_index_full_cleaned.to_csv(os.path.join(save_path, 'original_index_full_cleaned.csv'), index=False)\n",
    "\n",
    "# Save subsampled cleaned\n",
    "X_subsampled.to_csv(os.path.join(save_path, 'X_subsampled.csv'), index=False)\n",
    "y_subsampled.to_csv(os.path.join(save_path, 'y_subsampled.csv'), index=False)\n",
    "lat_lon_subsampled.to_csv(os.path.join(save_path, 'lat_lon_subsampled.csv'), index=False)\n",
    "original_index_subsampled.to_csv(os.path.join(save_path, 'original_index_subsampled.csv'), index=False)\n",
    "\n",
    "print(\"Saved all files: X, y, lat_lon, and original_index for both full cleaned and subsampled datasets!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
